y = wx + b 선형 모델 (x = data) =  뉴런
mse = 평균제곱오차 (오차들을 제곱하여 평균내는것)
역치 = 뉴런이 외부 신호를 자극 받았을떄 그 신호가 역치이상이면 인식하고 아니면 버리는 특징 => 활성화 함수

뉴런 + 역치 =  신경망 => 퍼셉트론 = 선형함수(뉴런) + 활성화함수(역치)
mlp: Multilayer Perceptron 
mlp가 층이 깊어지고 뉴런의 수가 많아지면 가중치 수가 급격히 늘어남
->mlp 신경망을 이미지 처리에 사용한다면 이미지의 어떤 특정 패턴이 존재하는 위치에 민감하게 동작하기 때문에 이미지크기를 맞추어야한다

cnn: 특징을 학습시키기때문에 위치나 크기가 달라져도 '특징'을 통해 유추할 수 있다.

cnn구조: Feature Extractor(특징추출) x a + Classifier(mlp, 분류)
Feature Extractor 구조: Convolution Layer(특징 추출) + Pooling Layer(불필요한 부분 삭제)

cnn 에는 필터라는 것의 개념이있는데 돋보기와 비슷한 역할이라고 생각하면 된다.
Padding(패딩): 필터의 크기로인해 가장자리부분의 데이터가 부족하여 입력과 출력의 크기가 달라질때 이
를 보정하기위해 가장자리부분에 0을 채워넣는 것 -> 가장자리특징을 더 잘 보기위함

스트라이드: 얼마나 픽셀을 건너뛰면서 수행할지를 결정하는 여부(따로 설정하지않으면 1)
